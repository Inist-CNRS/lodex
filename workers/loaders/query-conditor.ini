append = pack
label = query-conditor
extension = json
mimeType = application/json

# load some plugins to activate some statements
[use]
plugin = conditor
plugin = basics

# {{{
[TXTConcat]

[env]
path = q
value = self().trim()

[replace]
path = q
value = self().trim()

[CORHALFetch]
url = https://corhal-api.inist.fr
retries = 3
timeout = 60000

path = transformClassification
value = fix((str) => str \
    .replace(/\s*\[.*\]/gmi, "") \
    .replace(/and\/or/gm, "and or") \
    .split("/"))

[replace]

path = doi
value = get("doi","")

path = title
value = get("title.default","")

path = abstract
value = get('abstract.default',"")

path = authors
value = get("authors").map(item => _.assign(_.pick(item, ["fullname", "rnsr"]),{ affiliations: item.affiliations.map(aff => _.omit(aff,["isni", "idRef","ref"])) }))

path = addresses
value = get("authors").map(author => author.affiliations.map(aff => aff.address))

path = rnsr
value = get("authors").thru(authors => _.chain(authors) \
    .map("rnsr").flatten().concat( \
      _.chain(authors) \
        .map("affiliations").flatten().map("rnsr").flatten().value(), \
      _.chain(authors) \
        .map("affiliations").flatten().map("enrichments.rnsr").flatten().value() \
    ).uniq().compact().value())

path = publicationYear
value = get("business.xPublicationDate").map(item=>_.first(_.split(item,"-"))).min()

path = unpaywall
value = get("enrichments.openAccess.unpaywall", {}) \
  .thru(u => ({ \
    oaStatus: _.get(u, "oaStatus", "Inconnu") === "Inconnu" ? "Inconnu" : _.capitalize(_.get(u, "oaStatus")), \
    isOa: _.get(u, "isOa") === true ? "Oui" : _.get(u, "isOa") === false ? "Non" : "Inconnu", \
    hostType: _.chain(_.get(u, "oaLocations", [{"hostType": "Inconnu"}])).map("hostType").uniq() \
      .map(host => host === "repository" ? "Archive seule" : host === "publisher" ? "Editeur seul" : host) \
      .thru(arr => _.size(arr) === 2 ? "Commun" : _.size(arr) === 0 ? "Closed" : arr).toString().value()}))

path = fulltextUrl
value = get("fulltextUrl","")

path = documentType
value = get("business.duplicateGenre","")

path = halId
value = get("halId","")

path = halIndexedClassification
value = get("classifications.hal").map(item => env("transformClassification")(item.en)) \
    .map(subArray =>subArray.map((classif, index) => classif ? `${index + 1}-${classif}` : ""))

path = halPrimaryClassification
value = get("classifications.hal").map(item => _.first(env("transformClassification")(item.en))).uniq()

path = authorsKeywords
value = get("keywords.en.author",[]).map(item=>_.deburr(item)).uniq()

path = conferenceDetails
value = fix([self.host.conference.name,self.host.conference.date,self.host.conference.place,self.host.conference.country]).compact().join(" ")

path = volumeIssueAndPages
value = fix(`${self.host.volume} / ${self.host.issue} / ${self.host.pages.range}`).replace(/undefined/gmi,"")

path = host
value = get("host").pick(['title','publisher','issn','isbn','eissn','language']) \
  .thru(host => _.defaults(host, { publisher: "Inconnu", title: "Inconnu" }))

path = sourceUidChain
value = get("business.sourceUidChain")

# Ensures that each object contains an identification key (required by lodex)
[swing]
test = pick(['URI', 'uri']).pickBy(_.identity).isEmpty()
[swing/identify]

# Ignore objects with duplicate URI
[dedupe]
ignore = true

# Prevent keys from containing dot path notation (which is forbidden by nodejs mongoDB driver)
[OBJFlatten]
separator = fix('.')
reverse = true
safe = true

# Uncomment to see each data sent to the database
#[debug]

# Add contextual metadata related to the import
[assign]
path = lodexStamp.importedDate
value = fix(new Date()).thru(d => new Intl.DateTimeFormat('fr-FR', { year: 'numeric', month: 'long', day: 'numeric' }).format(d))
path = lodexStamp.query
value = env('q')
[assign]
path = lodexStamp.extractRnsrQueried
value = get("lodexStamp.query").invoke('match', /business\.authorsRnsr:([^\s]+)/).get(1)

[assign]
path = lodexStamp.extractDateRangeQueried
value = get("lodexStamp.query")\
  .thru(q => q.includes('business.xPublicationDate.normalized:[')\
    ? (q.match(/business\.xPublicationDate.normalized:\[([^\]]+)\]/)[1]).split(' TO ')\
    : [q.match(/business\.xPublicationDate.normalized:([^\s]+)/)[1]])\
  .thru(range => range.length === 1 ? [range[0], range[0]] : range)

[assign]
path = extractRnsrQueriedAddresses
value = get("authors").map(author => author.affiliations.filter(a => \
    _.includes(author?.rnsr, self.lodexStamp.extractRnsrQueried) || \
    _.includes(a?.rnsr, self.lodexStamp.extractRnsrQueried) || \
    _.includes(a?.enrichments?.rnsr, self.lodexStamp.extractRnsrQueried) \
  )).flatten().map("address")

[assign]
path = isOaEnriched
value = get("fulltextUrl").thru(text => !_.isEmpty(text)?"Oui":self.unpaywall.isOa)

path = indexedIn
value = get("sourceUidChain").replace(/\$.*?!/g,"!").split("!").compact()

[remove]
test = get("publicationYear").thru(year => year >=`${self.lodexStamp.extractDateRangeQueried[0]}` && year <= `${self.lodexStamp.extractDateRangeQueried[1]}`)
reverse = true
