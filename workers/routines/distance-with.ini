# For one document selected by a URI (otherwise the first of the stream),
# and with one field on parameter, we build a vector from the initial document
# and all documents that shared one or more values of the field
#
# Be carful :  works only with @ezs/lodex > 1.0.1

prepend = delegate?file=../worker.ini
mimeType = application/json
label = distinct

[use]
plugin = basics
plugin = lodex
plugin = analytics

[env]
path = connectionStringURI
value = get('connectionStringURI')

[buildContext]
connectionStringURI = env('connectionStringURI')

; On garde dans l'environnement quelques paramètres
[env]
path = minValue
value = env('minValue').split('§').map(parseFloat).shift().defaultTo(0)

path = maxValue
value = env('maxValue').split('§').map(parseFloat).shift().defaultTo(1)

path = maxSize
value = env('maxSize').parseInt().defaultTo(10)

path = reverse
value = env('orderBy').split('/').get(1).replace('asc', 0).replace('desc', 1).parseInt()

path = uri
value = get('filter.uri')

path = field
value = get('field').castArray()

; On récupére les documents filtrés
[LodexRunQuery]

; On supprime les infos inutiles
[filterVersions]
[filterContributions]

[shift]

# Préparation de la requete de rapprochement
[replace]
path = filter.uri.$ne
value = get('uri')

path = connectionStringURI
value = env('connectionStringURI')

path = referer
value = self()

[LodexRunQuery]

[env?singleton]
path = total
value = get('total').parseInt().defaultTo(0)

[filterVersions]
[filterContributions]

; On continue uniquement si il ya des résultats
[drop]
path = total
if = 0

; on démiliplie chaque object entrant en fonction du nombre de champ
[multiply]
path = pivotKey
value = env('field')

; On construit un objet avec uniquement les champs nécessaire au calcul de distance
[replace]
path = id1
value = get('referer.uri')

path = id2
value = get('uri')

path = value1
value = get(self.pivotKey)
path = value2
value = get('referer').get(self.pivotKey)

; Calcule de la distance entre 2 champs correspondant à 2 documents
[distance]
id = id1
id = id2
value = value1
value = value2

; On regroupe les valeurs par ID identique
[aggregate]

; on garde les différentes distances dans le champs values
; on donne au champ value la moyenne des distances
[assign]
path = values
value = get('value')

path = value
value = get('value').mean()


; On filtre les valeurs maximales du champ value
[greater]
than = env('minValue')

; On filtre les valeurs minimales du champ value
[less]
than = env('maxValue')

; On calcul un score pour permettre le tri
[tune]
path = env('tuneBy', 'value')

; On tri sur le champ value
[sort]
reverse = env('reverse')

; On garde uniqument les valeurs (donc on supprime les informations qui ont permis le tri)
[value]

; On envoit au client uniquement les premiers documents
[slice]
start = 1
size = env('maxSize')

; On prépare le json de sortie
[replace]
path = source
value = get('id.0')

path = target
value = get('id.1')

path = weight
value = get('value')

path = weights
value = get('values')

path = total
value = env('total')

path = maxSize
value = env('maxSize')

path = minValue
value = env('minValue')

path = maxValue
value = env('maxValue')

[injectSyndicationFrom]
connectionStringURI = env('connectionStringURI')
path = target

# On génére le json de sortie
[LodexOutput]
indent = true
extract = total
extract = maxSize
extract = maxValue
extract = minValue
